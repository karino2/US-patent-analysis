{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-extract-feature.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karino2/US-patent-analysis/blob/triplet_loss_colab/colab/bert_extract_feature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rQph610BeO4I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BERT feature extraction for grants and app**\n",
        "\n",
        "Extract bert feature for triplet loss.\n",
        "\n",
        "Porting to colab of feature extraction part below.\n",
        "\n",
        "https://github.com/yoheikikuta/US-patent-analysis/blob/master/notebook/tripletloss_model_with_circulum_learning.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "3Cv0EJiZ8vi6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3AyT0Fq8yzD",
        "colab_type": "code",
        "outputId": "1c07db3f-7dd6-42be-b11a-197d3b84e33d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.13.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "EWkrwgQV80JK",
        "colab_type": "code",
        "outputId": "ae2a5f47-7f0b-461a-f603-773c883279e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone -b docker https://github.com/yoheikikuta/bert.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "remote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (269/269), 220.79 KiB | 2.94 MiB/s, done.\n",
            "Resolving deltas: 100% (144/144), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eg8r8ARt89w3",
        "colab_type": "code",
        "outputId": "821e80c8-0b27-4ef8-f995-1391f54a135f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XG9_uLXKMf2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir ./bert/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-n-oE9aNPs6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zn-onntHM0lN",
        "colab_type": "code",
        "outputId": "2beb307a-8d2f-4300-a30f-f3773aa75369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://karino2-uspatent/features/test_grants_ids.pkl.gz ./bert/data/\n",
        "!gsutil cp gs://karino2-uspatent/features/training_app_ids.pkl.gz ./bert/data/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://karino2-uspatent/features/test_grants_ids.pkl.gz...\n",
            "/ [1 files][  3.0 MiB/  3.0 MiB]                                                \n",
            "Operation completed over 1 objects/3.0 MiB.                                      \n",
            "Copying gs://karino2-uspatent/features/training_app_ids.pkl.gz...\n",
            "/ [1 files][794.7 KiB/794.7 KiB]                                                \n",
            "Operation completed over 1 objects/794.7 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kywCunsPQxjZ",
        "colab_type": "code",
        "outputId": "c8aad845-597a-4d0b-9a13-52295707960a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "!ls ./bert/data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "citations_info_2000.df.gz  test_grants_ids.pkl.gz  training_app_1000.df.gz\n",
            "grants_for_2000.df.gz\t   testset_app_1000.df.gz  training_app_ids.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S1jf0kzIM0Ss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with gzip.open(\"./bert/data/test_grants_ids.pkl.gz\", 'rb') as f:\n",
        "     (test_ids, grants_ids) = pickle.load(f)\n",
        "with gzip.open(\"./bert/data/training_app_ids.pkl.gz\", 'rb') as f:\n",
        "     training_ids = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLWTT6NZ_ZYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check tpu name**"
      ]
    },
    {
      "metadata": {
        "id": "pShRjorw_Lla",
        "colab_type": "code",
        "outputId": "ab721d8f-fa7f-4181-f0aa-e620432119ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.81.75.66:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 10635577033367471859),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 976606133020435086),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4501356155637751213),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 13632525968536816513),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8641085653688703972),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 369903914460703330),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9085190748269255527),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10709987216607880277),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 4476668466533816992),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 4540033896122469206),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 266174668603247362)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lBOhgRrYGJzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bert setup"
      ]
    },
    {
      "metadata": {
        "id": "D9hQGFJRwbBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VOCAB_CONFIG_PATH=' gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12' #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hfcrTkmwNJE",
        "colab_type": "code",
        "outputId": "6fc17760-1a78-48ee-b164-0255176d0454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp {VOCAB_CONFIG_PATH}/vocab.txt ./bert/model/patent/vocab.txt\n",
        "!gsutil cp {VOCAB_CONFIG_PATH}/bert_config.json ./bert/model/patent/bert_config.json"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/vocab.txt...\n",
            "/ [1 files][226.1 KiB/226.1 KiB]                                                \n",
            "Operation completed over 1 objects/226.1 KiB.                                    \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_config.json...\n",
            "/ [1 files][  313.0 B/  313.0 B]                                                \n",
            "Operation completed over 1 objects/313.0 B.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWPKTaJ8viYi",
        "colab_type": "code",
        "outputId": "7187787a-25a4-4f72-d412-31b7a57f4ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls ./bert/model/patent"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_7OoVrSLxX2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LpSs4ff-xXc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./bert\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiCmZuxgN2rx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtR55qoWN2Uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=\"./bert/model/patent/vocab.txt\", do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgyWpBn-N99_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CLS_ID = tokenizer.vocab[\"[CLS]\"]\n",
        "SEP_ID = tokenizer.vocab[\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zu9nDflvDoHq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_seq_length = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRV-xNYdFumM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_single_sentence(ids_a_input, uniqueue_id):\n",
        "  ids_a = ids_a_input\n",
        "  # Account for [CLS] and [SEP] with \"- 2\"\n",
        "  if len(ids_a_input) > max_seq_length - 2:\n",
        "    ids_a = list(ids_a_input)[0:(max_seq_length - 2)]  \n",
        "      \n",
        "\n",
        "  # The convention in BERT is:\n",
        "  # (b) For single sequences:\n",
        "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "  #  type_ids: 0     0   0   0  0     0 0\n",
        "  #\n",
        "  # Where \"type_ids\" are used to indicate whether this is the first\n",
        "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "  # embedding vector (and position vector). This is not *strictly* necessary\n",
        "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "  # it easier for the model to learn the concept of sequences.\n",
        "  #\n",
        "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "  # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "  # the entire model is fine-tuned.\n",
        "  input_ids = []\n",
        "  segment_ids = []\n",
        "  input_ids.append(CLS_ID)\n",
        "  segment_ids.append(0)\n",
        "  for token in ids_a:\n",
        "    input_ids.append(token)\n",
        "    segment_ids.append(0)\n",
        "  input_ids.append(SEP_ID)\n",
        "  segment_ids.append(0)\n",
        "\n",
        "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "  # tokens are attended to.\n",
        "  input_mask = [1] * len(input_ids)\n",
        "\n",
        "  # Zero-pad up to the sequence length.\n",
        "  while len(input_ids) < max_seq_length:\n",
        "    input_ids.append(0)\n",
        "    input_mask.append(0)\n",
        "    segment_ids.append(0)\n",
        "\n",
        "  assert len(input_ids) == max_seq_length\n",
        "  assert len(input_mask) == max_seq_length\n",
        "  assert len(segment_ids) == max_seq_length\n",
        "\n",
        "  return (input_ids, input_mask, segment_ids, uniqueue_id)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aZoDPL9rtr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ODA4cgTN6nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BASE_TRAINING=10000\n",
        "BASE_TEST = 20000\n",
        "BASE_GRANTS = 30000\n",
        "\n",
        "\n",
        "# unique_id, tokens, input_ids, input_mask, input_type_ids\n",
        "def feature_tuplist_to_feature_dict(ftups):\n",
        "    dic = {}\n",
        "    dic['input_ids'] = [tup[0] for tup in ftups]\n",
        "    dic[\"input_mask\"] = [tup[1] for tup in ftups]\n",
        "    dic[\"input_type_ids\"] = [tup[2] for tup in ftups]\n",
        "    dic['unique_ids'] = [tup[3] for tup in ftups]\n",
        "    return dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qr6ULqjyzVHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pNzvdp26yo-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qf51QlG_zJ1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9U0S-hYxeMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import modeling\n",
        "import tokenization\n",
        "\n",
        "from extract_features  import model_fn_builder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AburDQpQxd_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(\"./bert/model/patent/bert_config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hGfDjS6x7fw",
        "colab_type": "code",
        "outputId": "a6a0a13d-36ef-44ce-e98e-13b111803bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "BUCKET = 'karino2-uspatent' #@param {type:\"string\"}\n",
        "OUTPUT_DIR = 'gs://{}/mlstudy-phys/bert/models/patent_1000'.format(BUCKET)\n",
        "\n",
        "INIT_CHECK_POINT_FILE='model.ckpt-1602' #@param {type:\"string\"}\n",
        "INIT_CHECK_POINT = '{}/{}'.format(OUTPUT_DIR, INIT_CHECK_POINT_FILE)\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "print('***** Init checkpoint: {} *****'.format(INIT_CHECK_POINT))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://karino2-uspatent/mlstudy-phys/bert/models/patent_1000 *****\n",
            "***** Init checkpoint: gs://karino2-uspatent/mlstudy-phys/bert/models/patent_1000/model.ckpt-1602 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7yRP7fE5qu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OISS39WWxdxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FLAGS(object):\n",
        "    '''Parameters.'''\n",
        "    def __init__(self):\n",
        "        self.vocab_file = \"./bert/model/patent/vocab.txt\"\n",
        "        self.use_tpu = True\n",
        "        self.output_dir = OUTPUT_DIR\n",
        "        # self.data_dir = \"./bert/data/1000\"\n",
        "        self.init_checkpoint = INIT_CHECK_POINT\n",
        "        self.predict_batch_size = 16\n",
        "        # TPU related\n",
        "        self.num_tpu_cores = 8\n",
        "        self.tpu_name = TPU_ADDRESS\n",
        "        \n",
        "        # following parameters are not used anymore. (because we create feature by hand)\n",
        "        self.do_lower_case = True\n",
        "        self.max_seq_length = 512\n",
        "        \n",
        "        # The following parameters are not used in predictions.\n",
        "        # Just use to create RunConfig.\n",
        "        self.master = None\n",
        "        self.save_checkpoints_steps = 1\n",
        "        self.learning_rate = 0\n",
        "        self.num_warmup_steps = 0\n",
        "        self.num_train_steps = 0\n",
        "        # TPU related. Some of these value have positive int not to make TPUEstimator angry (even though these are not used...).\n",
        "        self.eval_batch_size = 32\n",
        "        self.train_batch_size = 32 \n",
        "        self.iterations_per_loop = 1000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjiBu4fzxdjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FLAGS = FLAGS()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wvl80s6_zH_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu_name)\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    master=FLAGS.master,\n",
        "    model_dir=FLAGS.output_dir,\n",
        "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "        num_shards=FLAGS.num_tpu_cores,\n",
        "        per_host_input_for_training=is_per_host))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icN9SGPpzHxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    init_checkpoint=FLAGS.init_checkpoint,\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    layer_indexes=[-1],\n",
        "    use_one_hot_embeddings=FLAGS.use_tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOnW40GE9yTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/kyzhouhzau/BERT-NER/issues/19\n",
        "\n",
        "def model_fn_wrapper(features, labels, mode, params):\n",
        "  tspec = model_fn(features, labels, mode, params)\n",
        "  pred_dict = {'predictions': tspec.predictions['layer_output_0']}\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=tspec.mode, predictions=pred_dict, scaffold_fn=tspec.scaffold_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPgJuC0A9yAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    # model_fn=model_fn,\n",
        "    model_fn=model_fn_wrapper,\n",
        "    config=run_config,\n",
        "    train_batch_size=FLAGS.train_batch_size,\n",
        "    eval_batch_size=FLAGS.eval_batch_size,\n",
        "    predict_batch_size=FLAGS.predict_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8iT3Hw6R0oW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jllGtkdrOhli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "metadata": {
        "id": "HrlMr2n9LL-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_HdrvJ6I2k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_app_input_fdict = feature_tuplist_to_feature_dict([convert_single_sentence(one_app, BASE_TRAINING+idx) for idx, one_app in enumerate(training_ids)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddYAjKsyTCZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7oC91n9K7OU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ids_to_input_fdict(ids, base_id):\n",
        "  return feature_tuplist_to_feature_dict([convert_single_sentence(one_app, base_id+idx) for idx, one_app in enumerate(ids)])\n",
        "\n",
        "def fdict_to_features(fdict):\n",
        "\n",
        "  def _batch_input_function(params):\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(fdict)    \n",
        "    return test_ds.batch(params['batch_size'])\n",
        "\n",
        "  feature_results =  np.empty((0,768), float)\n",
        "  print(datetime.datetime.today())\n",
        "  result = estimator.predict(_batch_input_function, yield_single_examples=True)\n",
        "  \n",
        "  for one in result:\n",
        "    feature_results = np.append(feature_results, one['predictions'][0].reshape(1,768), axis=0 )  \n",
        "  print(datetime.datetime.today())\n",
        "  return feature_results\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9rU3-bb2WOVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "87694ae7-26f1-4c9a-8d1c-bb5080419f4b"
      },
      "cell_type": "code",
      "source": [
        "train_features = fdict_to_features(training_app_input_fdict)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-01 03:45:56.035574\n",
            "2019-03-01 03:46:21.520941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t0W-slIyLA2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5313ef2f-f474-4f1a-ebc4-13e1c8119e7b"
      },
      "cell_type": "code",
      "source": [
        "len(train_features)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "hHfYKTFoXGQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3307f285-26b7-4ae1-a3fa-29254cad93f5"
      },
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "5994daac-4d92-4cf6-fb7f-e7efda8f63fd",
        "id": "NqdtvMyOXJgI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_features[0, 0:5]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.04389739,  0.88131171, -0.35072595,  0.79031169, -0.26134047])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "mcpyP8Cxds8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e46213d1-022f-4766-bcee-6ca55675f80e"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with gzip.open(\"training_app_1000_features.pkl.gz\", 'w') as f:\n",
        "     pickle.dump(train_features, f)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.26 s, sys: 7.6 ms, total: 8.27 s\n",
            "Wall time: 8.28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PNF5tHrvdst2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "659d5a7b-b47b-4e88-b246-263966ebb696"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp training_app_1000_features.pkl.gz gs://karino2-uspatent/features/training_app_1000_features.pkl.gz"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://training_app_1000_features.pkl.gz [Content-Type=application/octet-stream]...\n",
            "-\n",
            "Operation completed over 1 objects/3.1 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "keYJ3Q4YXHsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e3577e2-eda0-40e0-cbe8-33f765a781e1"
      },
      "cell_type": "code",
      "source": [
        "!ls -l training_app_1000_features.pkl.gz"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 3262353 Mar  1 04:19 training_app_1000_features.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DUYfYE_5gimZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create test set application feature"
      ]
    },
    {
      "metadata": {
        "id": "znK50ExLgtvk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_app_input_fdict = ids_to_input_fdict(test_ids, BASE_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZ576bjNexU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c22f0db8-32ae-42f9-d45f-459136907d7b"
      },
      "cell_type": "code",
      "source": [
        "test_app_features = fdict_to_features(test_app_input_fdict)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-01 04:24:11.729741\n",
            "2019-03-01 04:24:41.610773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ifZt8jbftpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d7afc454-d6d7-4969-a93f-95c4bcf60cb2"
      },
      "cell_type": "code",
      "source": [
        "test_app_features[0, 0:5]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.2944594 ,  0.57456857, -0.08040974,  1.03909576,  0.08170709])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "MnfqaB5ggPLf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4762b9b6-542e-4a65-91c0-d230c976f3cd"
      },
      "cell_type": "code",
      "source": [
        "test_app_features.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "gqX-cbJhgO9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "72317f80-6e60-4f43-c39e-00ad3000b90d"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with gzip.open(\"test_app_1000_features.pkl.gz\", 'w') as f:\n",
        "     pickle.dump(test_app_features, f)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.15 s, sys: 2.93 ms, total: 8.15 s\n",
            "Wall time: 8.16 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hY6QjWcWgXLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "87691a3e-4367-45bf-f7ed-6d8d65c4af20"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp test_app_1000_features.pkl.gz gs://karino2-uspatent/features/test_app_1000_features.pkl.gz"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://test_app_1000_features.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  3.1 MiB/  3.1 MiB]                                                \n",
            "Operation completed over 1 objects/3.1 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZELEwWAIgW-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fJyBWmBgo4X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create grants2000 feature"
      ]
    },
    {
      "metadata": {
        "id": "4BDoJ0ZmgWwr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grants_input_fdict = ids_to_input_fdict(grants_ids, BASE_GRANTS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q4QtV9-5ftYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d9b4f489-75e4-4a9c-be16-2ccc9feb46b0"
      },
      "cell_type": "code",
      "source": [
        "grants_features = fdict_to_features(grants_input_fdict)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-03-01 04:30:05.723136\n",
            "2019-03-01 04:30:46.824327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jd6ph8rbhEZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e97e6d4c-dd65-4783-e437-496bfaba0d65"
      },
      "cell_type": "code",
      "source": [
        "grants_features.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2524, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "YS02_0KjhEI5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f78cb1c-2bf6-4780-b729-3e5c9f9bb7eb"
      },
      "cell_type": "code",
      "source": [
        "grants_features[0, 0:5]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.73496956,  1.23776925, -0.64043194,  0.28553247, -0.10149363])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "pY1uHPiihQsV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b2ffd103-a98d-49dc-8ef8-66cc8b11c740"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with gzip.open(\"grants_2000_features.pkl.gz\", 'w') as f:\n",
        "     pickle.dump(grants_features, f)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20.9 s, sys: 3.18 ms, total: 20.9 s\n",
            "Wall time: 20.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mNh-Y-lJhQeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1fedf8e5-3cf9-4615-ccd3-16780115a86e"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp grants_2000_features.pkl.gz gs://karino2-uspatent/features/grants_2000_features.pkl.gz"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://grants_2000_features.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  7.9 MiB/  7.9 MiB]                                                \n",
            "Operation completed over 1 objects/7.9 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NyAIFC5lLAgh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-ml34rye2gN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Check to kikuta-san's data\n",
        "\n",
        "Seems different. We don't know the reason."
      ]
    },
    {
      "metadata": {
        "id": "MCt5a7vIapC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a882d064-7bc4-403a-9bb2-60c751db4394"
      },
      "cell_type": "code",
      "source": [
        "!mkdir kikuta_feature"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘kikuta_feature’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LHpKBUTTarnv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "b9bdb884-2a10-4ae9-e8a8-126e623ea834"
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://yohei-kikuta/mlstudy-phys/bert/data/1000/* kikuta_feature/"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/bert_extracted_feature_test_1000.pkl...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/bert_extracted_feature_train_1000.pkl...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/citations_info_2000.df.gz...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/dev.tsv...\n",
            "| [4 files][122.2 MiB/122.2 MiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/grants_feature_2000.pkl...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/grants_for_2000.df.gz...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/testset_app_1000.df.gz...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/testset_app_feature_1000.pkl...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/train.tsv...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/training_app_1000.df.gz...\n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/data/1000/training_app_feature_1000.pkl...\n",
            "| [11 files][253.9 MiB/253.9 MiB]   12.7 MiB/s                                  \n",
            "Operation completed over 11 objects/253.9 MiB.                                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j8OIv7aWarY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2dcdda54-6ff0-4760-f0db-1d34421caa8a"
      },
      "cell_type": "code",
      "source": [
        "!ls -l kikuta_feature/training_app_feature_1000.pkl"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 6187667 Mar  1 04:03 kikuta_feature/training_app_feature_1000.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gF_f_B4nbDuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a8e39850-0220-4c46-b5a6-c5f261fcb139"
      },
      "cell_type": "code",
      "source": [
        "ls -l training_app_ids.pkl.gz"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 813752 Mar  1 02:14 training_app_ids.pkl.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w-AUVm7dbMyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kikuta_training_df = pd.read_pickle(\"kikuta_feature/training_app_feature_1000.pkl\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsCHZafHbXw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1546
        },
        "outputId": "dedfd03a-c2fd-4c7f-b87b-384e9eab05bc"
      },
      "cell_type": "code",
      "source": [
        "kikuta_training_df['feature'][0]  == train_features[0,]"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "qadwMOpnbDfc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d376b2e-9725-4eb5-9263-921ce7046284"
      },
      "cell_type": "code",
      "source": [
        "kikuta_training_df['feature'][0][0:5]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.80122775,  0.36823475, -0.40176541,  0.12356944,  0.34096408])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "rwrkN4z1b6KO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "587b4151-4d73-4f54-fae9-d6c67c0f99f1"
      },
      "cell_type": "code",
      "source": [
        "train_features[0, 0:5]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.04389739,  0.88131171, -0.35072595,  0.79031169, -0.26134047])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "VeR-Ulttb59w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "030f3e79-7510-4d0a-9a4c-336f08782af8"
      },
      "cell_type": "code",
      "source": [
        "kikuta_training_df['app_id'][0]"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14222691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "KYGMvrl1Jf-m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wJ-8XpqGIoaX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YT_q0cm5OpBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}