{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-benchmark-2000-save-result.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karino2/US-patent-analysis/blob/bert_input/colab/bert_benchmark_2000_save_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rQph610BeO4I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BERT on 2000-2000 prediction benchmark, save partial result**\n",
        "\n",
        "Benchmark 2000 seems too big to run on colab at once.\n",
        "So I create notebook to predict 20 application each.\n",
        "\n",
        "Basic code is from here: \n",
        "https://github.com/karino2/US-patent-analysis/blob/bert_input/colab/bert_benchmark_2000.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "3Cv0EJiZ8vi6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "import pickle\n",
        "import gzip\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R3AyT0Fq8yzD",
        "colab_type": "code",
        "outputId": "a599f9d2-ff47-4e3c-dc54-e67331295d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "EWkrwgQV80JK",
        "colab_type": "code",
        "outputId": "d075b641-c95b-4482-8f35-be1bea0b4914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone -b docker https://github.com/yoheikikuta/bert.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 269, done.\u001b[K\n",
            "Receiving objects:   0% (1/269)   \rReceiving objects:   1% (3/269)   \rReceiving objects:   2% (6/269)   \rReceiving objects:   3% (9/269)   \rReceiving objects:   4% (11/269)   \rReceiving objects:   5% (14/269)   \rReceiving objects:   6% (17/269)   \rReceiving objects:   7% (19/269)   \rReceiving objects:   8% (22/269)   \rReceiving objects:   9% (25/269)   \rReceiving objects:  10% (27/269)   \rReceiving objects:  11% (30/269)   \rReceiving objects:  12% (33/269)   \rReceiving objects:  13% (35/269)   \rReceiving objects:  14% (38/269)   \rReceiving objects:  15% (41/269)   \rReceiving objects:  16% (44/269)   \rReceiving objects:  17% (46/269)   \rReceiving objects:  18% (49/269)   \rReceiving objects:  19% (52/269)   \rReceiving objects:  20% (54/269)   \rReceiving objects:  21% (57/269)   \rReceiving objects:  22% (60/269)   \rReceiving objects:  23% (62/269)   \rReceiving objects:  24% (65/269)   \rReceiving objects:  25% (68/269)   \rReceiving objects:  26% (70/269)   \rReceiving objects:  27% (73/269)   \rReceiving objects:  28% (76/269)   \rReceiving objects:  29% (79/269)   \rReceiving objects:  30% (81/269)   \rReceiving objects:  31% (84/269)   \rReceiving objects:  32% (87/269)   \rReceiving objects:  33% (89/269)   \rReceiving objects:  34% (92/269)   \rReceiving objects:  35% (95/269)   \rReceiving objects:  36% (97/269)   \rReceiving objects:  37% (100/269)   \rReceiving objects:  38% (103/269)   \rReceiving objects:  39% (105/269)   \rReceiving objects:  40% (108/269)   \rReceiving objects:  41% (111/269)   \rReceiving objects:  42% (113/269)   \rReceiving objects:  43% (116/269)   \rReceiving objects:  44% (119/269)   \rReceiving objects:  45% (122/269)   \rReceiving objects:  46% (124/269)   \rReceiving objects:  47% (127/269)   \rReceiving objects:  48% (130/269)   \rReceiving objects:  49% (132/269)   \rReceiving objects:  50% (135/269)   \rReceiving objects:  51% (138/269)   \rReceiving objects:  52% (140/269)   \rReceiving objects:  53% (143/269)   \rReceiving objects:  54% (146/269)   \rReceiving objects:  55% (148/269)   \rReceiving objects:  56% (151/269)   \rReceiving objects:  57% (154/269)   \rremote: Total 269 (delta 0), reused 0 (delta 0), pack-reused 269\u001b[K\n",
            "Receiving objects:  58% (157/269)   \rReceiving objects:  59% (159/269)   \rReceiving objects:  60% (162/269)   \rReceiving objects:  61% (165/269)   \rReceiving objects:  62% (167/269)   \rReceiving objects:  63% (170/269)   \rReceiving objects:  64% (173/269)   \rReceiving objects:  65% (175/269)   \rReceiving objects:  66% (178/269)   \rReceiving objects:  67% (181/269)   \rReceiving objects:  68% (183/269)   \rReceiving objects:  69% (186/269)   \rReceiving objects:  70% (189/269)   \rReceiving objects:  71% (191/269)   \rReceiving objects:  72% (194/269)   \rReceiving objects:  73% (197/269)   \rReceiving objects:  74% (200/269)   \rReceiving objects:  75% (202/269)   \rReceiving objects:  76% (205/269)   \rReceiving objects:  77% (208/269)   \rReceiving objects:  78% (210/269)   \rReceiving objects:  79% (213/269)   \rReceiving objects:  80% (216/269)   \rReceiving objects:  81% (218/269)   \rReceiving objects:  82% (221/269)   \rReceiving objects:  83% (224/269)   \rReceiving objects:  84% (226/269)   \rReceiving objects:  85% (229/269)   \rReceiving objects:  86% (232/269)   \rReceiving objects:  87% (235/269)   \rReceiving objects:  88% (237/269)   \rReceiving objects:  89% (240/269)   \rReceiving objects:  90% (243/269)   \rReceiving objects:  91% (245/269)   \rReceiving objects:  92% (248/269)   \rReceiving objects:  93% (251/269)   \rReceiving objects:  94% (253/269)   \rReceiving objects:  95% (256/269)   \rReceiving objects:  96% (259/269)   \rReceiving objects:  97% (261/269)   \rReceiving objects:  98% (264/269)   \rReceiving objects:  99% (267/269)   \rReceiving objects: 100% (269/269)   \rReceiving objects: 100% (269/269), 174.41 KiB | 2.64 MiB/s, done.\n",
            "Resolving deltas:   0% (0/155)   \rResolving deltas:   3% (5/155)   \rResolving deltas:   5% (8/155)   \rResolving deltas:  10% (16/155)   \rResolving deltas:  17% (27/155)   \rResolving deltas:  20% (32/155)   \rResolving deltas:  34% (53/155)   \rResolving deltas:  36% (57/155)   \rResolving deltas:  40% (63/155)   \rResolving deltas:  43% (67/155)   \rResolving deltas:  83% (129/155)   \rResolving deltas:  88% (137/155)   \rResolving deltas: 100% (155/155)   \rResolving deltas: 100% (155/155), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eg8r8ARt89w3",
        "colab_type": "code",
        "outputId": "cb58dc85-f27c-4c1c-9aba-04a841d082b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  bert\tresult_0_50480.pkl.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zgPiQOJRMgxt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data setup\n",
        "\n",
        "Data setup is based on https://github.com/karino2/US-patent-analysis/blob/bert_input/colab/bert_tokenized_claim_setup.ipynb"
      ]
    },
    {
      "metadata": {
        "id": "XG9_uLXKMf2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir ./bert/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-n-oE9aNPs6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zn-onntHM0lN",
        "colab_type": "code",
        "outputId": "098b0f23-0a29-4630-a345-870014672d4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://karino2-uspatent/features/test_grants_ids.pkl.gz ./bert/data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://karino2-uspatent/features/test_grants_ids.pkl.gz...\n",
            "/ [1 files][  3.0 MiB/  3.0 MiB]                                                \n",
            "Operation completed over 1 objects/3.0 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S1jf0kzIM0Ss",
        "colab_type": "code",
        "outputId": "d0d441f6-b66e-4350-8739-031e281ea35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "with gzip.open(\"./bert/data/test_grants_ids.pkl.gz\", 'rb') as f:\n",
        "     (test_ids, grants_ids) = pickle.load(f)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 375 ms, sys: 135 ms, total: 510 ms\n",
            "Wall time: 516 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_oPSPIxXM0Ba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLWTT6NZ_ZYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Check tpu name**"
      ]
    },
    {
      "metadata": {
        "id": "pShRjorw_Lla",
        "colab_type": "code",
        "outputId": "40c22318-4710-41c9-88a9-481c2e27c82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.15.120.218:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 4298392443942794684),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1923170471964936461),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 6228095721152161989),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 6732931291765328744),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6798991559338036958),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 15873917152675780060),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 199907361241214455),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5734044260161643251),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 482559865321732734),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 5132300039592469076),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 12997989039417537483),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12193158781450699725)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vh1zryY9NO4X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6JlAViHNOna",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DmoRhs9E791",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAHOWYzlC3l5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBOhgRrYGJzS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bert setup"
      ]
    },
    {
      "metadata": {
        "id": "D9hQGFJRwbBl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "VOCAB_CONFIG_PATH=' gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12' #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hfcrTkmwNJE",
        "colab_type": "code",
        "outputId": "b9d911d5-4b02-4f36-81db-6d573b79790c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp {VOCAB_CONFIG_PATH}/vocab.txt ./bert/model/patent/vocab.txt\n",
        "!gsutil cp {VOCAB_CONFIG_PATH}/bert_config.json ./bert/model/patent/bert_config.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/vocab.txt...\n",
            "- [1 files][226.1 KiB/226.1 KiB]                                                \n",
            "Operation completed over 1 objects/226.1 KiB.                                    \n",
            "Copying gs://yohei-kikuta/mlstudy-phys/bert/models/pre-trained-models/uncased_L-12_H-768_A-12/bert_config.json...\n",
            "/ [1 files][  313.0 B/  313.0 B]                                                \n",
            "Operation completed over 1 objects/313.0 B.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XWPKTaJ8viYi",
        "colab_type": "code",
        "outputId": "ddfb61c6-2bfe-4b92-a664-33095f78d457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!ls ./bert/model/patent"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_config.json  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_7OoVrSLxX2i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LpSs4ff-xXc4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./bert\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aiCmZuxgN2rx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZtR55qoWN2Uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=\"./bert/model/patent/vocab.txt\", do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgyWpBn-N99_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CLS_ID = tokenizer.vocab[\"[CLS]\"]\n",
        "SEP_ID = tokenizer.vocab[\"[SEP]\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7eF3NHnxN9v8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CLJu1tSKe5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "  \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "  # This is a simple heuristic which will always truncate the longer sequence\n",
        "  # one token at a time. This makes more sense than truncating an equal percent\n",
        "  # of tokens from each, since if one sequence is very short then each token\n",
        "  # that's truncated likely contains more information than a longer sequence.\n",
        "  while True:\n",
        "    total_length = len(tokens_a) + len(tokens_b)\n",
        "    if total_length <= max_length:\n",
        "      break\n",
        "    if len(tokens_a) > len(tokens_b):\n",
        "      tokens_a.pop()\n",
        "    else:\n",
        "      tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s1IMQ8o6su3T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "label_list = [\"not_entailment\", \"entailment\"]\n",
        "max_seq_length = 512\n",
        "\n",
        "label_map = {}\n",
        "for (i, label) in enumerate(label_list):\n",
        "  label_map[label] = i"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1KJ2xS5aI1G4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def original_convert_single_pair(ids_a_input, ids_b_input):\n",
        "\n",
        "  # Clone and pop for truncate. Most of the case result len is the same for our purpose, but try simple implementation first.\n",
        "  ids_a = list(ids_a_input)\n",
        "  ids_b = list(ids_b_input)\n",
        "    \n",
        "  # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "  # length is less than the specified length.\n",
        "  # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "  _truncate_seq_pair(ids_a, ids_b, max_seq_length - 3)\n",
        "\n",
        "  # The convention in BERT is:\n",
        "  # (a) For sequence pairs:\n",
        "  #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "  #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "  # (b) For single sequences:\n",
        "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "  #  type_ids: 0     0   0   0  0     0 0\n",
        "  #\n",
        "  # Where \"type_ids\" are used to indicate whether this is the first\n",
        "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "  # embedding vector (and position vector). This is not *strictly* necessary\n",
        "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "  # it easier for the model to learn the concept of sequences.\n",
        "  #\n",
        "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "  # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "  # the entire model is fine-tuned.\n",
        "  input_ids = []\n",
        "  segment_ids = []\n",
        "  input_ids.append(CLS_ID)\n",
        "  segment_ids.append(0)\n",
        "  for token in ids_a:\n",
        "    input_ids.append(token)\n",
        "    segment_ids.append(0)\n",
        "  input_ids.append(SEP_ID)\n",
        "  segment_ids.append(0)\n",
        "\n",
        "  for token in ids_b:\n",
        "    input_ids.append(token)\n",
        "    segment_ids.append(1)\n",
        "  input_ids.append(SEP_ID)\n",
        "  segment_ids.append(1)\n",
        "\n",
        "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "  # tokens are attended to.\n",
        "  input_mask = [1] * len(input_ids)\n",
        "\n",
        "  # Zero-pad up to the sequence length.\n",
        "  while len(input_ids) < max_seq_length:\n",
        "    input_ids.append(0)\n",
        "    input_mask.append(0)\n",
        "    segment_ids.append(0)\n",
        "\n",
        "  assert len(input_ids) == max_seq_length\n",
        "  assert len(input_mask) == max_seq_length\n",
        "  assert len(segment_ids) == max_seq_length\n",
        "\n",
        "  return (input_ids, input_mask, segment_ids)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ka67cUqvrzSn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimization for our application\n",
        "\n",
        "dup ids consume huge memory.\n",
        "We cach and use the same memory if ids_a_nput and ids_b_input have enough size."
      ]
    },
    {
      "metadata": {
        "id": "vS4V68lnteSp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NORMAL_INPUT_MASK = [1]*max_seq_length\n",
        "NORMAL_SEGMENT_IDS = [0]*257+[1]*255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WepvGg7GzBHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jU7GTdsDu3pr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# [CLS](0), 1-255(len=255), [SEP], 257-510(len=254), [SEP]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qEiIH_OYvdoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LEN_255_CACHE = {}\n",
        "LEN_254_CACHE = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3MXXhPIlwnpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def truncage_with_cache(ids, target_len):\n",
        "  if target_len == 255:\n",
        "    cache = LEN_255_CACHE\n",
        "  else:\n",
        "    assert target_len == 254\n",
        "    cache = LEN_254_CACHE\n",
        "  if ids not in cache:\n",
        "    cache[ids] = ids[0:target_len]\n",
        "  return cache[ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-aZoDPL9rtr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fast_convert_single_pair(ids_a_input, ids_b_input):  \n",
        "  if (len(ids_a_input) < 256) or (len(ids_b_input) < 256) :\n",
        "    return original_convert_single_pair(ids_a_input, ids_b_input)\n",
        "  \n",
        "  ids_a = truncage_with_cache(ids_a_input, 255)\n",
        "  ids_b = truncage_with_cache(ids_b_input, 254)\n",
        "\n",
        "  input_ids = (CLS_ID,) + ids_a + (SEP_ID,) + ids_b + (SEP_ID,)\n",
        "  \n",
        "  return (input_ids, NORMAL_INPUT_MASK, NORMAL_SEGMENT_IDS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ODA4cgTN6nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def feature_tuplist_to_feature_dict(ftups):\n",
        "    dic = {}\n",
        "    dic['input_ids'] = [tup[0] for tup in ftups]\n",
        "    dic[\"input_mask\"] = [tup[1] for tup in ftups]\n",
        "    dic[\"segment_ids\"] = [tup[2] for tup in ftups]\n",
        "    dic[\"label_ids\"] = [[0] for _ in ftups]\n",
        "    return dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qr6ULqjyzVHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0_nu01-zV1t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "List is not hashable, but all element is int and tuple is hashable in this case. We use this ids as key for caching."
      ]
    },
    {
      "metadata": {
        "id": "pNzvdp26yo-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_ids_tup = [tuple(ids) for ids in test_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qf51QlG_zJ1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grants_ids_tup = [tuple(ids) for ids in grants_ids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0DHSLYROsL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pairs = [(\"{}_{}\".format(i, j), app_claim, grants_claim) for i, app_claim in enumerate(test_ids_tup) for j, grants_claim in enumerate(grants_ids_tup)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VyxfkdbUOb6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWSDncX5Obqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3wmUzm3N2Cc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_9U0S-hYxeMY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import modeling\n",
        "import tokenization\n",
        "\n",
        "from run_classifier import model_fn_builder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AburDQpQxd_k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bert_config = modeling.BertConfig.from_json_file(\"./bert/model/patent/bert_config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hGfDjS6x7fw",
        "colab_type": "code",
        "outputId": "04d0939a-6a1c-4c69-9f20-dd74c7c3a083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "BUCKET = 'karino2-uspatent' #@param {type:\"string\"}\n",
        "OUTPUT_DIR = 'gs://{}/mlstudy-phys/bert/models/patent_1000'.format(BUCKET)\n",
        "\n",
        "INIT_CHECK_POINT_FILE='model.ckpt-1602' #@param {type:\"string\"}\n",
        "INIT_CHECK_POINT = '{}/{}'.format(OUTPUT_DIR, INIT_CHECK_POINT_FILE)\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "print('***** Init checkpoint: {} *****'.format(INIT_CHECK_POINT))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://karino2-uspatent/mlstudy-phys/bert/models/patent_1000 *****\n",
            "***** Init checkpoint: gs://karino2-uspatent/mlstudy-phys/bert/models/patent_1000/model.ckpt-1602 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D7yRP7fE5qu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OISS39WWxdxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FLAGS(object):\n",
        "    '''Parameters.'''\n",
        "    def __init__(self):\n",
        "        self.vocab_file = \"./bert/model/patent/vocab.txt\"\n",
        "        self.use_tpu = True\n",
        "        self.output_dir = OUTPUT_DIR\n",
        "        # self.data_dir = \"./bert/data/1000\"\n",
        "        self.init_checkpoint = INIT_CHECK_POINT\n",
        "        self.predict_batch_size = 16\n",
        "        # TPU related\n",
        "        self.num_tpu_cores = 8\n",
        "        self.tpu_name = TPU_ADDRESS\n",
        "        \n",
        "        # following parameters are not used anymore. (because we create feature by hand)\n",
        "        self.do_lower_case = True\n",
        "        self.max_seq_length = 512\n",
        "        \n",
        "        # The following parameters are not used in predictions.\n",
        "        # Just use to create RunConfig.\n",
        "        self.master = None\n",
        "        self.save_checkpoints_steps = 1\n",
        "        self.learning_rate = 0\n",
        "        self.num_warmup_steps = 0\n",
        "        self.num_train_steps = 0\n",
        "        # TPU related. Some of these value have positive int not to make TPUEstimator angry (even though these are not used...).\n",
        "        self.eval_batch_size = 32\n",
        "        self.train_batch_size = 32 \n",
        "        self.iterations_per_loop = 1000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YjiBu4fzxdjY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FLAGS = FLAGS()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wvl80s6_zH_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tokenizer = tokenization.FullTokenizer(\n",
        "#    vocab_file=FLAGS.vocab_file, do_lower_case=FLAGS.do_lower_case)\n",
        "\n",
        "# tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu_name).get_master()\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=FLAGS.tpu_name)\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    master=FLAGS.master,\n",
        "    model_dir=FLAGS.output_dir,\n",
        "    save_checkpoints_steps=FLAGS.save_checkpoints_steps,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=FLAGS.iterations_per_loop,\n",
        "        num_shards=FLAGS.num_tpu_cores,\n",
        "        per_host_input_for_training=is_per_host))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "icN9SGPpzHxe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_fn = model_fn_builder(\n",
        "    bert_config=bert_config,\n",
        "    num_labels=len([\"not_entailment\", \"entailment\"]),\n",
        "    init_checkpoint=FLAGS.init_checkpoint,\n",
        "    learning_rate=FLAGS.learning_rate,\n",
        "    num_train_steps=FLAGS.num_train_steps,\n",
        "    num_warmup_steps=FLAGS.num_warmup_steps,\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    use_one_hot_embeddings=FLAGS.use_tpu)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOnW40GE9yTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# https://github.com/kyzhouhzau/BERT-NER/issues/19\n",
        "\n",
        "def model_fn_wrapper(features, labels, mode, params):\n",
        "  tspec = model_fn(features, labels, mode, params)\n",
        "  pred_dict = {'predictions': tspec.predictions}\n",
        "  return tf.contrib.tpu.TPUEstimatorSpec(\n",
        "          mode=tspec.mode, predictions=pred_dict, scaffold_fn=tspec.scaffold_fn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPgJuC0A9yAq",
        "colab_type": "code",
        "outputId": "ad4826ae-acfd-41ca-cfe7-8f27e3201814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "cell_type": "code",
      "source": [
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=FLAGS.use_tpu,\n",
        "    # model_fn=model_fn,\n",
        "    model_fn=model_fn_wrapper,\n",
        "    config=run_config,\n",
        "    train_batch_size=FLAGS.train_batch_size,\n",
        "    eval_batch_size=FLAGS.eval_batch_size,\n",
        "    predict_batch_size=FLAGS.predict_batch_size)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_wrapper at 0x7feec6096158>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://karino2-uspatent/mlstudy-phys/bert/models/patent_1000', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      value: \"10.15.120.218:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feec608da90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': b'grpc://10.15.120.218:8470', '_evaluation_master': b'grpc://10.15.120.218:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.contrib.cluster_resolver.python.training.tpu_cluster_resolver.TPUClusterResolver object at 0x7feec60959b0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t8iT3Hw6R0oW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jllGtkdrOhli",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Whole data set is too big for memory\n",
        "\n",
        "Specify which block we will handle."
      ]
    },
    {
      "metadata": {
        "id": "k-pGh5kQa59H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94aaf6b6-7039-4548-83c3-faca01315fb7"
      },
      "cell_type": "code",
      "source": [
        "WHOLE_APP_NUM=1000\n",
        "\n",
        "WHOLE_PAIR_NUM = len(pairs)\n",
        "WHOLE_GRANTS_NUM = WHOLE_PAIR_NUM//WHOLE_APP_NUM\n",
        "WHOLE_PAIR_NUM, WHOLE_GRANTS_NUM"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2524000, 2524)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "_QX-E_u_bWVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BLOCK_SIZE = 20*WHOLE_GRANTS_NUM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M8Evu2zabkjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "07106373-09fa-44e8-a45a-6336b2f0a26b"
      },
      "cell_type": "code",
      "source": [
        "TOTAL_BLOCK_NUM = WHOLE_PAIR_NUM//BLOCK_SIZE\n",
        "BLOCK_SIZE, TOTAL_BLOCK_NUM"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50480, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "YT_q0cm5OpBd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xhr4HQUechh7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_pairs(pair_begin, pair_end):\n",
        "  fdict = feature_tuplist_to_feature_dict([fast_convert_single_pair(tup[1], tup[2]) for tup in pairs[pair_begin:pair_end]])\n",
        "  \n",
        "  def _batch_input_function(params):\n",
        "    test_ds = tf.data.Dataset.from_tensor_slices(fdict)    \n",
        "    return test_ds.batch(params['batch_size'])\n",
        "  \n",
        "  result = estimator.predict(_batch_input_function)\n",
        "  result = list(result)\n",
        "  print(datetime.datetime.today())\n",
        "  \n",
        "  return  [pred['predictions'] for pred in result]\n",
        "\n",
        "def predict_block_and_save_result(block_id):\n",
        "  pair_begin = (block_id)*BLOCK_SIZE\n",
        "  pair_end = (block_id+1)*BLOCK_SIZE\n",
        "  print(\"{}: start predict {}-{}\".format(datetime.datetime.today(), pair_begin, pair_end))\n",
        "\n",
        "  result_unwrap = predict_pairs(pair_begin, pair_end)\n",
        "  \n",
        "  filename = \"result_{}_{}.pkl.gz\".format(pair_begin, pair_end)\n",
        "  \n",
        "  with gzip.open(filename, 'w') as f:\n",
        "     pickle.dump(result_unwrap, f)\n",
        "  !gsutil cp {filename} gs://karino2-uspatent/features/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iym9RNXyooaX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Logging takes very long time (it takes 42min for 5min task.)\n",
        "Disable it."
      ]
    },
    {
      "metadata": {
        "id": "9ThSpYj23uGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73qTTs4n5IVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Block_id is from 0 to 49.\n",
        "\n",
        "Cell below takes about 4min."
      ]
    },
    {
      "metadata": {
        "id": "rO1LR3michOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "1bbc53fa-130f-485c-9329-c3e9aa406676"
      },
      "cell_type": "code",
      "source": [
        "#block_id 0 to 49\n",
        "# predict_block_and_save_result(0)\n",
        "# predict_block_and_save_result(1)\n",
        "# predict_block_and_save_result(2)\n",
        "\n",
        "predict_block_and_save_result(3)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-09 04:29:50.068956: start predict 151440-201920\n",
            "2019-01-09 04:33:41.288760\n",
            "Copying file://result_151440_201920.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O3Xvq1sWpz65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpwBH2Cx5SlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "22e841bf-214b-42f5-9910-999099e3f135"
      },
      "cell_type": "code",
      "source": [
        "predict_block_and_save_result(4)\n",
        "predict_block_and_save_result(5)\n",
        "predict_block_and_save_result(6)\n",
        "predict_block_and_save_result(7)\n",
        "predict_block_and_save_result(8)\n",
        "predict_block_and_save_result(9)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-09 04:36:16.297004: start predict 201920-252400\n",
            "2019-01-09 04:40:08.073022\n",
            "Copying file://result_201920_252400.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n",
            "2019-01-09 04:40:12.637301: start predict 252400-302880\n",
            "2019-01-09 04:44:02.763365\n",
            "Copying file://result_252400_302880.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n",
            "2019-01-09 04:44:08.222916: start predict 302880-353360\n",
            "2019-01-09 04:48:01.175177\n",
            "Copying file://result_302880_353360.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n",
            "2019-01-09 04:48:05.784844: start predict 353360-403840\n",
            "2019-01-09 04:51:56.431148\n",
            "Copying file://result_353360_403840.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n",
            "2019-01-09 04:52:01.042688: start predict 403840-454320\n",
            "2019-01-09 04:55:54.088656\n",
            "Copying file://result_403840_454320.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n",
            "2019-01-09 04:55:59.574419: start predict 454320-504800\n",
            "2019-01-09 04:59:52.251572\n",
            "Copying file://result_454320_504800.pkl.gz [Content-Type=application/octet-stream]...\n",
            "/ [1 files][  1.0 MiB/  1.0 MiB]                                                \n",
            "Operation completed over 1 objects/1.0 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0dwznoic5ST4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52eb8513-5b55-469b-b0a8-82bc129b920a"
      },
      "cell_type": "code",
      "source": [
        "for i in range(10, 20):\n",
        "  predict_block_and_save_result(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-01-09 05:02:12.300972: start predict 504800-555280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1zTX2bMv5SDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}