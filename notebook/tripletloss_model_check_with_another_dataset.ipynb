{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check tripletloss model using another dataset\n",
    "\n",
    "- Dataset: Musk dataset https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29\n",
    "\n",
    "**As of now tripletloss model doesn't show any improvements.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Musk dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "musk_df = pd.read_csv(\"../data/clean2.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+1</td>\n",
       "      <td>46</td>\n",
       "      <td>-108</td>\n",
       "      <td>-60</td>\n",
       "      <td>-69</td>\n",
       "      <td>-117</td>\n",
       "      <td>49</td>\n",
       "      <td>38</td>\n",
       "      <td>-161</td>\n",
       "      <td>...</td>\n",
       "      <td>-308</td>\n",
       "      <td>52</td>\n",
       "      <td>-7</td>\n",
       "      <td>39</td>\n",
       "      <td>126</td>\n",
       "      <td>156</td>\n",
       "      <td>-50</td>\n",
       "      <td>-112</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUSK-211</td>\n",
       "      <td>211_1+10</td>\n",
       "      <td>41</td>\n",
       "      <td>-188</td>\n",
       "      <td>-145</td>\n",
       "      <td>22</td>\n",
       "      <td>-117</td>\n",
       "      <td>-6</td>\n",
       "      <td>57</td>\n",
       "      <td>-171</td>\n",
       "      <td>...</td>\n",
       "      <td>-59</td>\n",
       "      <td>-2</td>\n",
       "      <td>52</td>\n",
       "      <td>103</td>\n",
       "      <td>136</td>\n",
       "      <td>169</td>\n",
       "      <td>-61</td>\n",
       "      <td>-136</td>\n",
       "      <td>79</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1    2    3    4    5    6    7    8    9   ...   159  160  \\\n",
       "0  MUSK-211   211_1+1   46 -108  -60  -69 -117   49   38 -161 ...  -308   52   \n",
       "1  MUSK-211  211_1+10   41 -188 -145   22 -117   -6   57 -171 ...   -59   -2   \n",
       "\n",
       "   161  162  163  164  165  166  167  168  \n",
       "0   -7   39  126  156  -50 -112   96  1.0  \n",
       "1   52  103  136  169  -61 -136   79  1.0  \n",
       "\n",
       "[2 rows x 169 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musk_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes information:\n",
    "\n",
    "```\n",
    "   Attribute:           Description:\n",
    "   molecule_name:       Symbolic name of each molecule.  Musks have names such\n",
    "                        as MUSK-188.  Non-musks have names such as\n",
    "                        NON-MUSK-jp13.\n",
    "   conformation_name:   Symbolic name of each conformation.  These\n",
    "                        have the format MOL_ISO+CONF, where MOL is the\n",
    "                        molecule number, ISO is the stereoisomer\n",
    "                        number (usually 1), and CONF is the\n",
    "                        conformation number. \n",
    "   f1 through f162:     These are \"distance features\" along rays (see\n",
    "                        paper cited above).  The distances are\n",
    "                        measured in hundredths of Angstroms.  The\n",
    "                        distances may be negative or positive, since\n",
    "                        they are actually measured relative to an\n",
    "                        origin placed along each ray.  The origin was\n",
    "                        defined by a \"consensus musk\" surface that is\n",
    "                        no longer used.  Hence, any experiments with\n",
    "                        the data should treat these feature values as\n",
    "                        lying on an arbitrary continuous scale.  In\n",
    "                        particular, the algorithm should not make any\n",
    "                        use of the zero point or the sign of each\n",
    "                        feature value. \n",
    "   f163:                This is the distance of the oxygen atom in the\n",
    "                        molecule to a designated point in 3-space.\n",
    "                        This is also called OXY-DIS.\n",
    "   f164:                OXY-X: X-displacement from the designated\n",
    "                        point.\n",
    "   f165:                OXY-Y: Y-displacement from the designated\n",
    "                        point.\n",
    "   f166:                OXY-Z: Z-displacement from the designated\n",
    "                        point. \n",
    "   class:               0 => non-musk, 1 => musk\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MUSK-211', 'MUSK-212', 'MUSK-213', 'MUSK-214', 'MUSK-215',\n",
       "       'MUSK-217', 'MUSK-219', 'MUSK-224', 'MUSK-228', 'MUSK-238',\n",
       "       'MUSK-240', 'MUSK-256', 'MUSK-273', 'MUSK-284', 'MUSK-287',\n",
       "       'MUSK-294', 'MUSK-300', 'MUSK-306', 'MUSK-314', 'MUSK-321',\n",
       "       'MUSK-322', 'MUSK-323', 'MUSK-330', 'MUSK-331', 'MUSK-333',\n",
       "       'MUSK-344', 'MUSK-f152', 'MUSK-f158', 'MUSK-j33', 'MUSK-j51',\n",
       "       'MUSK-jf15', 'MUSK-jf17', 'MUSK-jf46', 'MUSK-jf47', 'MUSK-jf58',\n",
       "       'MUSK-jf59', 'MUSK-jf66', 'MUSK-jf67', 'MUSK-jf78', 'NON-MUSK-192',\n",
       "       'NON-MUSK-197', 'NON-MUSK-199', 'NON-MUSK-200', 'NON-MUSK-207',\n",
       "       'NON-MUSK-208', 'NON-MUSK-210', 'NON-MUSK-216', 'NON-MUSK-220',\n",
       "       'NON-MUSK-226', 'NON-MUSK-232', 'NON-MUSK-233', 'NON-MUSK-244',\n",
       "       'NON-MUSK-249', 'NON-MUSK-251', 'NON-MUSK-252', 'NON-MUSK-253',\n",
       "       'NON-MUSK-270', 'NON-MUSK-271', 'NON-MUSK-286', 'NON-MUSK-288',\n",
       "       'NON-MUSK-289', 'NON-MUSK-290', 'NON-MUSK-295', 'NON-MUSK-296',\n",
       "       'NON-MUSK-297', 'NON-MUSK-305', 'NON-MUSK-308', 'NON-MUSK-309',\n",
       "       'NON-MUSK-318', 'NON-MUSK-319', 'NON-MUSK-320', 'NON-MUSK-326',\n",
       "       'NON-MUSK-327', 'NON-MUSK-328', 'NON-MUSK-332', 'NON-MUSK-334',\n",
       "       'NON-MUSK-338', 'NON-MUSK-358', 'NON-MUSK-360', 'NON-MUSK-361',\n",
       "       'NON-MUSK-362', 'NON-MUSK-f146', 'NON-MUSK-f150', 'NON-MUSK-f161',\n",
       "       'NON-MUSK-f164', 'NON-MUSK-f209', 'NON-MUSK-j100', 'NON-MUSK-j129',\n",
       "       'NON-MUSK-j130', 'NON-MUSK-j146', 'NON-MUSK-j147', 'NON-MUSK-j148',\n",
       "       'NON-MUSK-j81', 'NON-MUSK-j83', 'NON-MUSK-j84', 'NON-MUSK-j90',\n",
       "       'NON-MUSK-j96', 'NON-MUSK-j97', 'NON-MUSK-jf18', 'NON-MUSK-jf79',\n",
       "       'NON-MUSK-jp10', 'NON-MUSK-jp13'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musk_df[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['211_1+1', '211_1+10', '211_1+11', ..., 'jp13_2+7', 'jp13_2+8',\n",
       "       'jp13_2+9'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musk_df[1].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use 2 ~ 167 columns as feature and 0,1 and 168 columns as labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traing with GBDT to check the problem difficulty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "musk_df = musk_df.sample(frac=1, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "musk_df = musk_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON-MUSK-j147</td>\n",
       "      <td>j147_4+189</td>\n",
       "      <td>37</td>\n",
       "      <td>-121</td>\n",
       "      <td>-105</td>\n",
       "      <td>128</td>\n",
       "      <td>-117</td>\n",
       "      <td>106</td>\n",
       "      <td>210</td>\n",
       "      <td>-18</td>\n",
       "      <td>...</td>\n",
       "      <td>-69</td>\n",
       "      <td>-193</td>\n",
       "      <td>-110</td>\n",
       "      <td>-118</td>\n",
       "      <td>68</td>\n",
       "      <td>234</td>\n",
       "      <td>-47</td>\n",
       "      <td>-178</td>\n",
       "      <td>145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON-MUSK-f146</td>\n",
       "      <td>f146_1+381</td>\n",
       "      <td>270</td>\n",
       "      <td>-194</td>\n",
       "      <td>-145</td>\n",
       "      <td>-62</td>\n",
       "      <td>-117</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>-171</td>\n",
       "      <td>...</td>\n",
       "      <td>-301</td>\n",
       "      <td>57</td>\n",
       "      <td>-135</td>\n",
       "      <td>-19</td>\n",
       "      <td>-13</td>\n",
       "      <td>226</td>\n",
       "      <td>-70</td>\n",
       "      <td>-39</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1    2    3    4    5    6    7    8    9   ...   \\\n",
       "0  NON-MUSK-j147  j147_4+189   37 -121 -105  128 -117  106  210  -18 ...    \n",
       "1  NON-MUSK-f146  f146_1+381  270 -194 -145  -62 -117   52   56 -171 ...    \n",
       "\n",
       "   159  160  161  162  163  164  165  166  167  168  \n",
       "0  -69 -193 -110 -118   68  234  -47 -178  145  0.0  \n",
       "1 -301   57 -135  -19  -13  226  -70  -39 -211  0.0  \n",
       "\n",
       "[2 rows x 169 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musk_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(musk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = musk_df.iloc[0:4000, 2:168]\n",
    "train_Y = musk_df.iloc[0:4000, 168]\n",
    "\n",
    "test_X = musk_df.iloc[4000:, 2:168]\n",
    "test_Y = musk_df.iloc[4000:, 168]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_child_weight': 2,\n",
    "    'gamma': 0.2,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.405072\n",
      "[2]\ttraining's binary_logloss: 0.376796\n",
      "[3]\ttraining's binary_logloss: 0.352722\n",
      "[4]\ttraining's binary_logloss: 0.330895\n",
      "[5]\ttraining's binary_logloss: 0.31256\n",
      "[6]\ttraining's binary_logloss: 0.295727\n",
      "[7]\ttraining's binary_logloss: 0.281168\n",
      "[8]\ttraining's binary_logloss: 0.267566\n",
      "[9]\ttraining's binary_logloss: 0.255118\n",
      "[10]\ttraining's binary_logloss: 0.243148\n",
      "[11]\ttraining's binary_logloss: 0.232214\n",
      "[12]\ttraining's binary_logloss: 0.222262\n",
      "[13]\ttraining's binary_logloss: 0.212953\n",
      "[14]\ttraining's binary_logloss: 0.204266\n",
      "[15]\ttraining's binary_logloss: 0.195906\n",
      "[16]\ttraining's binary_logloss: 0.188334\n",
      "[17]\ttraining's binary_logloss: 0.180681\n",
      "[18]\ttraining's binary_logloss: 0.173663\n",
      "[19]\ttraining's binary_logloss: 0.167115\n",
      "[20]\ttraining's binary_logloss: 0.160801\n",
      "[21]\ttraining's binary_logloss: 0.154902\n",
      "[22]\ttraining's binary_logloss: 0.149273\n",
      "[23]\ttraining's binary_logloss: 0.143978\n",
      "[24]\ttraining's binary_logloss: 0.139\n",
      "[25]\ttraining's binary_logloss: 0.134121\n",
      "[26]\ttraining's binary_logloss: 0.129465\n",
      "[27]\ttraining's binary_logloss: 0.125039\n",
      "[28]\ttraining's binary_logloss: 0.120981\n",
      "[29]\ttraining's binary_logloss: 0.116916\n",
      "[30]\ttraining's binary_logloss: 0.112905\n",
      "[31]\ttraining's binary_logloss: 0.109131\n",
      "[32]\ttraining's binary_logloss: 0.105455\n",
      "[33]\ttraining's binary_logloss: 0.102179\n",
      "[34]\ttraining's binary_logloss: 0.0990186\n",
      "[35]\ttraining's binary_logloss: 0.0958219\n",
      "[36]\ttraining's binary_logloss: 0.0926478\n",
      "[37]\ttraining's binary_logloss: 0.0898508\n",
      "[38]\ttraining's binary_logloss: 0.0868903\n",
      "[39]\ttraining's binary_logloss: 0.084404\n",
      "[40]\ttraining's binary_logloss: 0.0817619\n",
      "CPU times: user 2.62 s, sys: 70 ms, total: 2.69 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=40,\n",
    "                valid_sets=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_prob = gbm.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label = [ 1 if elem >= 0.5 else 0 for elem in predict_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sum( np.array(predict_label) == np.array(test_Y) ) / len(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9634334103156275"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification problem is solvable (at least for GBDT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try triplet loss model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized_feature_dict = { \n",
    "    k:v/np.linalg.norm(v) \n",
    "    for k,v \n",
    "    in zip(train_X.index, [elem[1].values for elem in train_X.iterrows()]) # elem[1].values pick up features of each row\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 12s, sys: 890 ms, total: 2min 13s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sim_dict = {\n",
    "    idx:{ idx_:np.sum(train_normalized_feature_dict[idx]*train_normalized_feature_dict[idx_])\n",
    "            for idx_\n",
    "            in train_X.index } \n",
    "    for idx \n",
    "    in train_X.index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9182183781695297,\n",
       " 0.9190310498816693,\n",
       " 0.9240562721459058,\n",
       " 0.9272741728267794,\n",
       " 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted( sim_dict[0].values() )[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_similarity_by_value(sim_dict, app_id):\n",
    "    '''\n",
    "    input:\n",
    "        sim_dict: similary dictionary\n",
    "        app_id: target application id\n",
    "    return:\n",
    "        [(parsed1, sim1), (parsed2, sim2), ...] sorted by similarities\n",
    "    '''\n",
    "    return [(parsed, sim_dict[app_id][parsed]) for parsed in sorted(sim_dict[app_id], key=sim_dict[app_id].get)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uncited_grants_for_app_id(sim_dict, app_id, sidx, eidx, num, shuffle=True):\n",
    "    '''\n",
    "    input:\n",
    "        sim_dict: \n",
    "        app_id: target application id\n",
    "        sidx: start index to slice the sorted (parsed, sim) list\n",
    "        eidx: end index to slice the sorted (parsed, sim) list\n",
    "        num: number of grants that will be returned\n",
    "    return:\n",
    "        [parsed_1, parsed_2, ..., parsed_num] that are NOT cited to reject app_id\n",
    "    ''' \n",
    "    assert sidx != 0, \"Use except for 0 as sidx value\"\n",
    "    \n",
    "    sorted_grants_list = sort_similarity_by_value(sim_dict, app_id)\n",
    "    unsimilar_list = sorted_grants_list[sidx:eidx]\n",
    "    similar_list = sorted_grants_list[-eidx:-sidx]\n",
    "    if shuffle:\n",
    "        random.shuffle(unsimilar_list)\n",
    "        random.shuffle(similar_list)\n",
    "    \n",
    "    unsimilar_pairs = []\n",
    "    similar_pairs = []\n",
    "    \n",
    "    idx = 0\n",
    "    while len(unsimilar_pairs) != num:\n",
    "        id_unsimilar_pair = unsimilar_list[idx][0]\n",
    "        id_similar_pair = similar_list[idx][0]\n",
    "        if train_Y[id_unsimilar_pair] == 0 and train_Y[id_similar_pair] == 1:\n",
    "            unsimilar_pairs.append(id_unsimilar_pair)\n",
    "            similar_pairs.append(id_similar_pair)\n",
    "        idx += 1\n",
    "        \n",
    "    return unsimilar_pairs, similar_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return different uncited grants each call, change random seed as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1247, 665, 3234, 325], [1445, 2516, 3042, 3800])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "make_uncited_grants_for_app_id(sim_dict, 0, 1, 500, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2401, 302, 3655, 1082], [2682, 484, 165, 1445])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "make_uncited_grants_for_app_id(sim_dict, 0, 1, 500, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_triplet_pairs(sidx, eidx):\n",
    "    all_elems = []\n",
    "    \n",
    "    for idx in train_X.index:\n",
    "        unsimilar_pairs, similar_pairs = make_uncited_grants_for_app_id(sim_dict, idx, sidx, eidx, 1)\n",
    "        \n",
    "        for similar_idx, unsimilar_idx in zip(similar_pairs, unsimilar_pairs):\n",
    "            all_elems.append([idx, similar_idx, unsimilar_idx])\n",
    "    \n",
    "    result_df = pd.DataFrame(all_elems)\n",
    "    result_df.columns = ['idx', 'similar_idx', 'unsimilar_idx']\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 50 ms, total: 20.7 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random.seed(0)\n",
    "test = create_triplet_pairs(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>similar_idx</th>\n",
       "      <th>unsimilar_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1445</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2166</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  similar_idx  unsimilar_idx\n",
       "0    0         1445           1247\n",
       "1    1         2166            175"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.W = tfe.Variable( tf.random_normal( [self.input_shape, self.output_shape] ), name='weight' )\n",
    "        self.B = tfe.Variable( tf.random_normal( [self.output_shape] ), name='bias' ) \n",
    "        self.variables = [ self.W, self.B ]\n",
    "    \n",
    "    def frwrd_pass(self,X_train):\n",
    "        out = tf.matmul( X_train, self.W ) + self.B\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried more complex models, but they didn't show any improvements.\n",
    "\n",
    "\n",
    "```\n",
    "class Model(object):\n",
    "    def __init__(self, input_shape, output_shape1, output_shape2):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape1 = output_shape1\n",
    "        self.output_shape2 = output_shape2\n",
    "        self.W1 = tfe.Variable( tf.random_normal( [self.input_shape, self.output_shape1] ), name='weight' )\n",
    "        self.B1 = tfe.Variable( tf.random_normal( [self.output_shape1] ), name='bias' ) \n",
    "        self.W2 = tfe.Variable( tf.random_normal( [self.output_shape1, self.output_shape2] ), name='weight' )\n",
    "        self.B2 = tfe.Variable( tf.random_normal( [self.output_shape2] ), name='bias' ) \n",
    "        self.variables = [ self.W1, self.B1, self.W2, self.B2 ]\n",
    "    \n",
    "    def frwrd_pass(self,X_train):\n",
    "        out = tf.matmul( X_train, self.W1 ) + self.B1\n",
    "        out = tf.nn.relu(out)\n",
    "        out = tf.matmul( out, self.W2 ) + self.B2\n",
    "        \n",
    "        return out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tripletloss(anchor_out, positive_out, negative_out, margin=0.2):\n",
    "    norm_a_out = tf.nn.l2_normalize(anchor_out, axis=1)\n",
    "    norm_p_out = tf.nn.l2_normalize(positive_out, axis=1)\n",
    "    norm_n_out = tf.nn.l2_normalize(negative_out, axis=1)\n",
    "    \n",
    "    d_pos = tf.losses.cosine_distance(norm_a_out, norm_p_out, axis=1, reduction=tf.losses.Reduction.NONE)\n",
    "    d_neg = tf.losses.cosine_distance(norm_a_out, norm_n_out, axis=1, reduction=tf.losses.Reduction.NONE)\n",
    "    \n",
    "    loss = tf.maximum(0.0, margin + d_pos - d_neg)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_input_np(sidx, eidx):\n",
    "    anchor_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    \n",
    "    triplet_pairs = create_triplet_pairs(sidx, eidx)\n",
    "    \n",
    "    for row in triplet_pairs.itertuples():\n",
    "        anchor_list.append(train_normalized_feature_dict[row.idx])\n",
    "        positive_list.append(train_normalized_feature_dict[row.similar_idx])\n",
    "        negative_list.append(train_normalized_feature_dict[row.unsimilar_idx])\n",
    "    \n",
    "    return np.array([np.array(anchor_list), np.array(positive_list), np.array(negative_list)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_changing_negative_pair(sidx, eidx, batch_size, epochs):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.00001)\n",
    "    \n",
    "    seed = 0\n",
    "    for i in range(epochs):\n",
    "        seed += 1\n",
    "        random.seed(seed)\n",
    "        \n",
    "        input_data_np = create_training_input_np(sidx, eidx)\n",
    "        data_num = int(input_data_np.shape[1])\n",
    "        rand_idx = np.random.permutation(data_num)\n",
    "        index_data_np = np.array([\n",
    "            input_data_np[0][rand_idx], \n",
    "            input_data_np[1][rand_idx], \n",
    "            input_data_np[2][rand_idx]])\n",
    "\n",
    "        input_data = tf.convert_to_tensor(input_data_np, dtype=tf.float32)\n",
    "        anchor_data, positive_data, negative_data = input_data\n",
    "\n",
    "        for iter_id in range(data_num // batch_size):        \n",
    "            with tf.GradientTape() as tape:\n",
    "                anchor_out = model.frwrd_pass(anchor_data[iter_id*batch_size : (iter_id+1)*batch_size])\n",
    "                positive_out = model.frwrd_pass(positive_data[iter_id*batch_size : (iter_id+1)*batch_size])\n",
    "                negative_out = model.frwrd_pass(negative_data[iter_id*batch_size : (iter_id+1)*batch_size])\n",
    "                curr_loss = tripletloss(anchor_out, positive_out, negative_out)\n",
    "            grads = tape.gradient( curr_loss, model.variables )\n",
    "            optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print( \"Loss at step {:d}: {:.5f}\".format(i, curr_loss) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end_index_pairs = (\n",
    "    (1000, 2000),\n",
    "    (2000, 3000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_shape=166, output_shape=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start index: 1000, end index: 2000\n",
      "Loss at step 0: 0.10612\n",
      "Loss at step 10: 0.10253\n",
      "Loss at step 20: 0.07504\n",
      "Loss at step 30: 0.06947\n",
      "Loss at step 40: 0.08785\n",
      "Loss at step 50: 0.07011\n",
      "   start index: 2000, end index: 3000\n",
      "Loss at step 0: 0.34330\n",
      "Loss at step 10: 0.29408\n",
      "Loss at step 20: 0.32570\n",
      "Loss at step 30: 0.28743\n",
      "Loss at step 40: 0.24244\n",
      "Loss at step 50: 0.21860\n",
      "CPU times: user 53min 38s, sys: 2.34 s, total: 53min 41s\n",
      "Wall time: 53min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for sidx, eidx in start_end_index_pairs:\n",
    "    print(\"   start index: {}, end index: {}\".format(sidx,eidx))\n",
    "    train_with_changing_negative_pair(sidx, eidx, batch_size=20, epochs=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../trained_model/tripletloss_musk/ckpt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs('../trained_model/tripletloss_musk', exist_ok=True)\n",
    "saver = tfe.Saver(model.variables)\n",
    "saver.save(\"../trained_model/tripletloss_musk/ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalized_feature_dict = { \n",
    "    k:v/np.linalg.norm(v) \n",
    "    for k,v \n",
    "    in zip(test_X.index, [elem[1].values for elem in test_X.iterrows()]) # elem[1].values pick up features of each row\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = sorted(test_normalized_feature_dict.keys())\n",
    "\n",
    "test_feature_tensors = tf.convert_to_tensor(\n",
    "    np.array([ test_normalized_feature_dict[k] for k in sorted_keys ]),\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extracted_features = model.frwrd_pass(test_feature_tensors).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2598, 50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_extracted_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_extracted_features_df = pd.DataFrame({ \n",
    "    'ids':sorted_keys, 'extracted_feature':[ v/np.linalg.norm(v) for v in test_extracted_features ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_feature</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.066523544, 0.20527224, 0.12628277, -0.1699...</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.13204022, 0.1919553, 0.23854902, 0.0546946...</td>\n",
       "      <td>4001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   extracted_feature   ids\n",
       "0  [-0.066523544, 0.20527224, 0.12628277, -0.1699...  4000\n",
       "1  [-0.13204022, 0.1919553, 0.23854902, 0.0546946...  4001"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_extracted_features_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y[4001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.8 s, sys: 250 ms, total: 52.1 s\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_sim_dict = {\n",
    "    idx:{ idx_:np.sum(test_normalized_feature_dict[idx]*test_normalized_feature_dict[idx_])\n",
    "            for idx_\n",
    "            in test_X.index } \n",
    "    for idx \n",
    "    in test_X.index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for idx in test_Y.index:\n",
    "    anchor_label = test_Y[idx]\n",
    "    topk_similar = sort_similarity_by_value(test_sim_dict, idx)[-100:-1]\n",
    "    \n",
    "    for target_idx, _ in topk_similar:\n",
    "        if test_Y[target_idx] == anchor_label:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257202\n",
      "205781\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5642, 0.9795089363407963),\n",
       " (5606, 0.9795310255088824),\n",
       " (4625, 0.9814915960083728),\n",
       " (6060, 0.9826777896705929),\n",
       " (5919, 0.9842811996045822),\n",
       " (4000, 1.0)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort_similarity_by_value(test_sim_dict, 4000)[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(test_Y[5919])\n",
    "# print(test_Y[6060])\n",
    "# print(test_Y[4625])\n",
    "# print(test_Y[5606])\n",
    "# print(test_Y[5642])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 250 ms, total: 41.8 s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_sim_dict_predict = {\n",
    "    idx:{ idx_:np.sum(v*v_)\n",
    "            for idx_, v_\n",
    "            in zip(test_extracted_features_df['ids'], test_extracted_features_df['extracted_feature']) } \n",
    "    for idx, v\n",
    "    in zip(test_extracted_features_df['ids'], test_extracted_features_df['extracted_feature'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for idx in test_Y.index:\n",
    "    anchor_label = test_Y[idx]\n",
    "    topk_similar = sort_similarity_by_value(test_sim_dict_predict, idx)[-100:-1]\n",
    "    \n",
    "    for target_idx, _ in topk_similar:\n",
    "        if test_Y[target_idx] == anchor_label:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257202\n",
      "202296\n"
     ]
    }
   ],
   "source": [
    "print(len(result))\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5642, 0.9848649),\n",
       " (6060, 0.98657715),\n",
       " (4625, 0.9879164),\n",
       " (5217, 0.9881265),\n",
       " (5919, 0.9921755),\n",
       " (4000, 1.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort_similarity_by_value(test_sim_dict_predict, 4000)[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(test_Y[5919])\n",
    "# print(test_Y[5217])\n",
    "# print(test_Y[4625])\n",
    "# print(test_Y[6060])\n",
    "# print(test_Y[5642])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===== Trial and error ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
